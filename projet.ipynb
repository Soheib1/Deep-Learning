{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from data import load_dataset_and_make_dataloaders\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        image_channels: int,\n",
    "        nb_channels: int,\n",
    "        num_blocks: int,\n",
    "        cond_channels: int,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.noise_emb = NoiseEmbedding(cond_channels)\n",
    "        self.conv_in = nn.Conv2d(image_channels, nb_channels, kernel_size=3, padding=1)\n",
    "        self.blocks = nn.ModuleList([\n",
    "            ResidualBlock(nb_channels, cond_channels) for _ in range(num_blocks)\n",
    "        ])\n",
    "        self.conv_out = nn.Conv2d(nb_channels, image_channels, kernel_size=3, padding=1)\n",
    "    \n",
    "    def forward(self, noisy_input: torch.Tensor, c_noise: torch.Tensor) -> torch.Tensor:\n",
    "        # Generate noise embedding\n",
    "        cond = self.noise_emb(c_noise)  # [batch_size, cond_channels]\n",
    "\n",
    "        # Pass through input convolution\n",
    "        x = self.conv_in(noisy_input)\n",
    "\n",
    "        # Pass through residual blocks with noise conditioning\n",
    "        for block in self.blocks:\n",
    "            x = block(x, cond)\n",
    "\n",
    "        # Output convolution to return the denoised image\n",
    "        return self.conv_out(x)\n",
    "\n",
    "\n",
    "class NoiseEmbedding(nn.Module):\n",
    "    \"\"\"\n",
    "    The NoiseEmbedding module generates a sinusoidal embedding for a given noise level.\n",
    "    It takes a 1D tensor representing the noise level and produces a 2D tensor with\n",
    "    concatenated cosine and sine values of the noise level scaled by a learned weight.\n",
    "    \n",
    "    This embedding can be used to condition the model on different noise levels, which\n",
    "    is useful in tasks such as denoising or generative modeling where the noise level\n",
    "    plays a significant role.\n",
    "    \"\"\"\n",
    "    def __init__(self, cond_channels: int) -> None:\n",
    "        super().__init__()\n",
    "        assert cond_channels % 2 == 0\n",
    "        self.register_buffer('weight', torch.randn(1, cond_channels // 2))\n",
    "    \n",
    "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
    "        assert input.ndim == 1\n",
    "        f = 2 * torch.pi * input.unsqueeze(1) @ self.weight\n",
    "        return torch.cat([f.cos(), f.sin()], dim=-1)\n",
    "\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, nb_channels: int, cond_channels: int) -> None:\n",
    "        super().__init__()\n",
    "        self.norm1 = nn.BatchNorm2d(nb_channels)\n",
    "        self.conv1 = nn.Conv2d(nb_channels, nb_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.norm2 = nn.BatchNorm2d(nb_channels)\n",
    "        self.conv2 = nn.Conv2d(nb_channels, nb_channels, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        # Add a learnable linear layer to project the noise embedding\n",
    "        self.noise_projection = nn.Linear(cond_channels, nb_channels)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, cond: torch.Tensor) -> torch.Tensor:\n",
    "        # Project noise embedding to match the channel dimension of x\n",
    "        noise_emb = self.noise_projection(cond).unsqueeze(-1).unsqueeze(-1)\n",
    "        \n",
    "        # Add noise embedding to feature map before convolutions\n",
    "        y = self.conv1(F.relu(self.norm1(x + noise_emb)))\n",
    "        y = self.conv2(F.relu(self.norm2(y)))\n",
    "        return x + y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Step 1.0: Sample an image y from the dataset:\n",
    "gpu = torch.cuda.is_available()\n",
    "device = torch.device('cuda:0' if gpu else 'cpu')\n",
    " \n",
    "dl, info = load_dataset_and_make_dataloaders(\n",
    "    dataset_name='FashionMNIST',\n",
    "    root_dir='data', # choose the directory to store the data \n",
    "    batch_size=32,\n",
    "    num_workers=0,   # you can use more workers if you see the GPU is waiting for the batches\n",
    "    pin_memory=gpu,  # use pin memory if you're planning to move the data to GPU\n",
    ")\n",
    "sigma_data = info.sigma_data.to(device)  # Move sigma_data to GPU\n",
    "train_dl = dl.train\n",
    "test_dl = dl.valid\n",
    "#Step 1.1: Sample sigma from pnoise\n",
    "def sample_sigma(n, loc=-1.2, scale=1.2, sigma_min=2e-3, sigma_max=80):\n",
    "    return (torch.randn(n, device=device) * scale + loc).exp().clip(sigma_min, sigma_max)\n",
    "\n",
    "\n",
    "#Step 1.2: Add noise\n",
    "def add_noise_to_image(image, sigma, p_noise_mean=0, p_noise_std=1):\n",
    "    epsilon = torch.randn(image.shape, device=image.device) * p_noise_std + p_noise_mean\n",
    "    noisy_image = image + sigma * epsilon\n",
    "    noisy_image = torch.clamp(noisy_image, 0, 1)  # Ensure pixel values are within [0, 1]\n",
    "    return noisy_image\n",
    "\n",
    "#Step 1.3: Compute coefficients\n",
    "def c_in(sigma):\n",
    "    return 1/(torch.sqrt(sigma_data**2 + sigma**2))\n",
    "\n",
    "def c_out(sigma):\n",
    "    return sigma*sigma_data/(torch.sqrt(sigma_data**2 + sigma**2))\n",
    "\n",
    "def c_skip(sigma):\n",
    "    return sigma_data**2/(sigma_data**2 + sigma**2)\n",
    "\n",
    "def c_noise(sigma):\n",
    "    return torch.log(sigma)/4\n",
    "train_target = []\n",
    "sigma_batch = []\n",
    "noisy_train_input = []\n",
    "noisy_test_input = []\n",
    "s = True\n",
    "for images, _ in train_dl:\n",
    "    images = images.to(device)  # Move images to GPU\n",
    "    if s:\n",
    "        batch_siz = images.shape[0]\n",
    "        s = False\n",
    "    #For each batch, a different sigma\n",
    "    sigma = sample_sigma(1).to(device)  # Ensure sigma is on GPU\n",
    "    sigma_batch.append(sigma)\n",
    "    for sub_image in images:\n",
    "        noised_image = add_noise_to_image(sub_image, sigma)\n",
    "        noisy_train_input.append(noised_image * c_in(sigma))\n",
    "        train_target.append((sub_image - c_skip(sigma) * noised_image) / c_out(sigma))\n",
    "\n",
    "for images, _ in test_dl:\n",
    "    images = images.to(device)  # Move images to GPU\n",
    "    for sub_image in images:\n",
    "        #For each image, a different sigma, not storing the sigma this time\n",
    "        sigma = sample_sigma(1).to(device)  # Ensure sigma is on GPU\n",
    "        noised_image = add_noise_to_image(sub_image, sigma)\n",
    "        noisy_test_input.append(noised_image)\n",
    "\n",
    "noisy_train_input = torch.stack(noisy_train_input).float().to(device)  # Move to GPU\n",
    "train_target = torch.stack(train_target).float().to(device)  # Move to GPU\n",
    "noisy_test_input = torch.stack(noisy_test_input).float().to(device)  # Move to GPU\n",
    "sigma_batch = torch.stack(sigma_batch).float().to(device)  # Move to GPU\n",
    "c_noise_list = c_noise(sigma_batch).to(device)  # Move to GPU\n",
    "\n",
    "train_dataset = TensorDataset(noisy_train_input, train_target)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_siz, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = 0.1\n",
    "image_channels = 1  # FashionMnist images have 1 channel\n",
    "nb_channels = 16\n",
    "num_blocks = 4\n",
    "cond_channels = 8\n",
    "model = Model(image_channels, nb_channels, num_blocks, cond_channels).to(device)\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=eta)\n",
    "\n",
    "# Training loop\n",
    "nb_epochs = 100\n",
    "for epoch in tqdm(range(nb_epochs), desc=\"Training\"):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch_idx, (x_batch, t_batch) in enumerate(train_loader):\n",
    "        x_batch = x_batch.to(device)  # Move to GPU\n",
    "        t_batch = t_batch.to(device)  # Move to GPU\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        output = model(x_batch, c_noise_list[batch_idx])\n",
    "\n",
    "        # Compute loss over the batch, returns average loss per sample in the batch\n",
    "        loss = criterion(output, t_batch)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate loss\n",
    "        total_loss += loss.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing loop\n",
    "model.eval()\n",
    "def build_sigma_schedule(steps, rho=7, sigma_min=2e-3, sigma_max=80):\n",
    "    min_inv_rho = sigma_min ** (1 / rho)\n",
    "    max_inv_rho = sigma_max ** (1 / rho)\n",
    "    sigmas = (max_inv_rho + torch.linspace(0, 1, steps) * (min_inv_rho - max_inv_rho)) ** rho\n",
    "    return sigmas\n",
    "\n",
    "def D(x, sigma):\n",
    "    return c_skip(sigma) * x + c_out(sigma) * model(c_in(sigma) * x, c_noise(sigma))\n",
    "\n",
    "sigmas = build_sigma_schedule(50).to(device)  # Ensure sigmas are on GPU\n",
    "def euler_step(x):\n",
    "    batch_size = x.size(0)\n",
    "    for i, sigma in enumerate(sigmas):\n",
    "        sigma = sigma.to(device)  # Ensure sigma is on GPU\n",
    "        sigma = sigma.expand(batch_size)  # Expand sigma to match batch size\n",
    "        with torch.no_grad():\n",
    "            x_denoised = D(x, sigma)  \n",
    "            # Where D(x, sigma) = cskip(sigma) * x + cout(sigma) * F(cin(sigma) * x, cnoise(sigma)) \n",
    "            # and F(.,.) is your neural network\n",
    "        \n",
    "        sigma_next = sigmas[i + 1] if i < len(sigmas) - 1 else 0\n",
    "        d = (x - x_denoised) / sigma\n",
    "        \n",
    "        x = x + d * (sigma_next - sigma)  # Perform one step of Euler's method\n",
    "    return x\n",
    "\n",
    "# Visualize the first 5 noisy test images and their denoised versions\n",
    "fig, axes = plt.subplots(5, 2, figsize=(10, 20))\n",
    "for i in range(5):\n",
    "    noisy_image = noisy_test_input[i].unsqueeze(0)  # Add batch dimension\n",
    "    denoised_image = euler_step(noisy_image).squeeze(0)  # Remove batch dimension\n",
    "\n",
    "    # Plot noisy image\n",
    "    axes[i, 0].imshow(noisy_image.squeeze().cpu().numpy(), cmap='gray')\n",
    "    axes[i, 0].set_title(\"Noisy Image\")\n",
    "    axes[i, 0].axis('off')\n",
    "\n",
    "    # Plot denoised image\n",
    "    axes[i, 1].imshow(denoised_image.squeeze().cpu().numpy(), cmap='gray')\n",
    "    axes[i, 1].set_title(\"Denoised Image\")\n",
    "    axes[i, 1].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
